{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3954cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus\n",
    "# tokenization\n",
    "# vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5247d61",
   "metadata": {},
   "source": [
    "# corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97181307",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"I think almost everyone used social media now. Not everyone. Twitter is our parent’s social media, instagram is our social media. Instagram suits gen-z  more comparatively . Twitter is more professional whereas instagram is more fun types. Twitter is political, whereas instagram is more of a gossip club, you can stack someone, since its more like a portfolio, usually used by models, celebrities, entertainers etc.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a2bba",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1819fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization:\n",
    "\n",
    "# Yes, tokenization can remove stopwords in NLP. \n",
    "# Stopwords are commonly used words that may not carry much information and may be able to be removed with little information loss.\n",
    "# Tokenization is a technique for breaking down a piece of text into small units, called tokens. \n",
    "# To remove stopwords, the sentences must be converted into word tokens first, and then the stop words can be removed using a function like `remove_stopwords()`.\n",
    "# The NLTK library in Python has a list of stopwords stored in 16 different languages, including English.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f59d5",
   "metadata": {},
   "source": [
    "### Token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "316b1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae6b2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a16fd3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\excel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a0d5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokens = word_tokenize(corpus)\n",
    "#print(w_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732f970",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17f5e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\excel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e8ad195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8095aef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['think', 'almost', 'everyone', 'used', 'social', 'media', '.', 'everyone', '.', 'Twitter', 'parent', '’', 'social', 'media', ',', 'instagram', 'social', 'media', '.', 'Instagram', 'suits', 'gen-z', 'comparatively', '.', 'Twitter', 'professional', 'whereas', 'instagram', 'fun', 'types', '.', 'Twitter', 'political', ',', 'whereas', 'instagram', 'gossip', 'club', ',', 'stack', 'someone', ',', 'since', 'like', 'portfolio', ',', 'usually', 'used', 'models', ',', 'celebrities', ',', 'entertainers', 'etc', '.']\n"
     ]
    }
   ],
   "source": [
    "# removing stopwords\n",
    "filteredlist = [word for word in w_tokens if word.lower() not in stop_words]\n",
    "print(filteredlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a417a52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['think', 'almost', 'everyone', 'used', 'social', 'media', 'everyone', 'Twitter', 'parent', 'social', 'media', 'instagram', 'social', 'media', 'Instagram', 'suits', 'comparatively', 'Twitter', 'professional', 'whereas', 'instagram', 'fun', 'types', 'Twitter', 'political', 'whereas', 'instagram', 'gossip', 'club', 'stack', 'someone', 'since', 'like', 'portfolio', 'usually', 'used', 'models', 'celebrities', 'entertainers', 'etc']\n"
     ]
    }
   ],
   "source": [
    "# removing special characteres using isalnum():\n",
    "filteredlist = [i for i in filteredlist if i.isalnum() == True]\n",
    "print(filteredlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232b306f",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62db3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence\n",
    "# vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2377f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Twitter is more of a professional setup, whereas instagram is unprofessional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45fd35c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# create list with each word\n",
    "# vectorize\n",
    "words = sentence.split(' ')   \n",
    "# words will be a list\n",
    "vector = []\n",
    "for i in words:\n",
    "    if i in filteredlist:\n",
    "        count = 1\n",
    "    else:\n",
    "        count = 0\n",
    "    vector.append(count)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c5a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
